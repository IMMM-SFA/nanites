{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tutorial:\n",
    "## Logistic regression for factor mapping\n",
    "This analysis performs scenario discovery through the use of logistic regression\n",
    "on three water users in a multi-stakeholder basin.\n",
    "\n",
    "The analysis is performed on data generated during a previous experiment, detailed at\n",
    "[Hadjimichael et al. (2020)](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2020EF001503).\n",
    "\n",
    "The experiment employed exploratory modeling to assess the impacts of several (hydrologic,\n",
    "infrastructural, societal) uncertain factors on water shortages experienced in a river basin in\n",
    "Colorado.\n",
    "\n",
    "<img src=\"./figs/basin_map.pdf\" width=\"300\">\n",
    "\n",
    "Focusing on decision-relevant metrics, the scenario discovery is applied to the shortages experienced\n",
    "by each individual user (i.e., not on a single basin-wide or sector-wide metric). For this training\n",
    "example, we'll be using three different water users, two irrigation users and one municipal user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1:  Load Latin Hypercube Sample and set up problem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_IDs = ['7000550','7200799','3704614']\n",
    "nStructures = len(all_IDs)\n",
    "LHsamples = np.loadtxt('./data/LHsamples_original_1000.txt')\n",
    "param_bounds=np.loadtxt('./data/uncertain_params_bounds.txt', usecols=(1,2))\n",
    "realizations = 10\n",
    "\n",
    "param_names=['IWRmultiplier','RESloss','TBDmultiplier','M_Imultiplier',\n",
    "             'Shoshone','ENVflows','EVAdelta','XBM_mu0','XBM_sigma0',\n",
    "             'XBM_mu1','XBM_sigma1','XBM_p00','XBM_p11', 'shift']\n",
    "\n",
    "SOW_values = np.array([1,1,1,1,0,0,1,1,1,1,1,0,0,0]) #Default parameter values for base SOW\n",
    "\n",
    "# Set arrays for shortage frequencies and magnitudes\n",
    "frequencies = np.arange(10, 110, 10)\n",
    "magnitudes = np.arange(10, 110, 10)\n",
    "\n",
    "heatmaps = [load_performance(all_IDs[i])/100 for i in range(len(all_IDs))]\n",
    "scores = [pd.read_csv(all_IDs[i] + '_pseudo_r_scores.csv', sep=\",\") for i in range(len(all_IDs))]\n",
    "\n",
    "freq = [1,0,0]\n",
    "mag = [7,3,7]\n",
    "\n",
    "fig, axes = plt.subplots(1,3, dpi=600)\n",
    "for i in range(len(axes.flat)):\n",
    "    ax = axes.flat[i]\n",
    "    allSOWsperformance = heatmaps[i]\n",
    "    all_pseudo_r_scores = scores[i]\n",
    "    dta = pd.DataFrame(data = np.repeat(LHsamples, realizations, axis = 0), columns=param_names)\n",
    "    dta['Success']=allSOWsperformance[freq[i],mag[i],:]\n",
    "    pseudo_r_scores=all_pseudo_r_scores[str(frequencies[freq[i]])+'yrs_'+str(magnitudes[mag[i]])+'prc'].values\n",
    "    top_predictors = np.argsort(pseudo_r_scores)[::-1][:2] #Sort scores and pick top 2 predictors\n",
    "    # define color map for dots representing SOWs in which the policy\n",
    "    # succeeds (light blue) and fails (dark red)\n",
    "    dot_cmap = mpl.colors.ListedColormap(np.array([[227,26,28],[166,206,227]])/255.0)\n",
    "    # define color map for probability contours\n",
    "    contour_cmap = mpl.cm.get_cmap('RdBu')\n",
    "    # define probability contours\n",
    "    contour_levels = np.arange(0.0, 1.05,0.1)\n",
    "    # define base values of the predictors\n",
    "    base = SOW_values[top_predictors]\n",
    "    ranges = param_bounds[top_predictors]\n",
    "    # define grid of x (1st predictor), and y (2nd predictor) dimensions\n",
    "    # to plot contour map over\n",
    "    xgrid = np.arange(param_bounds[top_predictors[0]][0],\n",
    "                      param_bounds[top_predictors[0]][1], np.around((ranges[0][1]-ranges[0][0])/500,decimals=4))\n",
    "    ygrid = np.arange(param_bounds[top_predictors[1]][0],\n",
    "                      param_bounds[top_predictors[1]][1], np.around((ranges[1][1]-ranges[1][0])/500,decimals=4))\n",
    "    all_predictors = [ dta.columns.tolist()[i] for i in top_predictors]\n",
    "    dta['Interaction'] = dta[all_predictors[0]]*dta[all_predictors[1]]\n",
    "    result = fitLogit(dta, [all_predictors[i] for i in [0,1]])\n",
    "    contourset = plotContourMap(ax, result, dta, contour_cmap,\n",
    "                                dot_cmap, contour_levels, xgrid,\n",
    "                                ygrid, all_predictors[0], all_predictors[1], base)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}